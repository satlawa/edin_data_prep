{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "#from geocube.api.core import make_geocube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = gpd.read_file(\"/home/philipp/Data/GIS/GIS_grid/test_set/grid_test_set.shp\")\n",
    "tamsweg = gpd.read_file(\"/mnt/data_2/2018_tamsweg/vector/grid/512_02m/tamsweg_512_02m.shp\")\n",
    "mariazell = gpd.read_file(\"/mnt/data_2/2017_mariazell/vector/grid/512_02m/mariazell_512_02m.shp\")\n",
    "traun = gpd.read_file(\"/mnt/data_2/2017_traun/vector/grid/512_02m/traun_512_02m.shp\")\n",
    "pinzgau = gpd.read_file(\"/mnt/data_2/2018_pinzgau/vector/grid/512_02m/pinzgau_512_02m.shp\")\n",
    "\n",
    "test_indxs = np.array(test['id'])\n",
    "tamsweg = np.array(tamsweg['id'])\n",
    "mariazell = np.array(mariazell['id'])\n",
    "traun = np.array(traun['id'])\n",
    "pinzgau = np.array(pinzgau['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 48905,  48906,  48955, ..., 308607, 308608, 308645])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_indxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reindex(train_idxs, test_idxs):\n",
    "    sub_train = []\n",
    "    sub_test = []\n",
    "    for i in range(train_idxs.size):\n",
    "        if train_idxs[i] in test_idxs:\n",
    "            sub_test.append(i)\n",
    "        else:\n",
    "            sub_train.append(i)\n",
    "    return {'train':np.array(sub_train), 'test':np.array(sub_test)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_indices(indices, interval, size, start=0):\n",
    "    '''\n",
    "    transform indices from id (shp) to index (hdf5)\n",
    "    '''\n",
    "    temp = []\n",
    "    \n",
    "    # loop for as long as interval is a multiple\n",
    "    for i in range(0, math.floor(size/interval)):\n",
    "        # filter for interval\n",
    "        inteval_idxs = indices[(indices>=i*interval) & (indices<(i+1)*interval)]\n",
    "        # creat helper variable\n",
    "        j = i*3*interval\n",
    "        # append all created sub indices\n",
    "        temp.append(np.concatenate([inteval_idxs+j, inteval_idxs+j+interval, inteval_idxs+j+2*interval, inteval_idxs+j+3*interval]))\n",
    "    \n",
    "    # rest of interval\n",
    "    rest = size % interval\n",
    "    # creat helper variable\n",
    "    j = (size - rest) * 3\n",
    "    inteval_idxs = indices[(indices>=size-rest) & (indices<size)]\n",
    "    # append all created sub indices\n",
    "    temp.append(np.concatenate([inteval_idxs+j, inteval_idxs+j+rest, inteval_idxs+j+2*rest, inteval_idxs+j+3*rest]))\n",
    "\n",
    "    # concatonate all\n",
    "    new_idxs = np.concatenate(temp)\n",
    "    \n",
    "    return new_idxs + start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_reg = []\n",
    "test_reg = []\n",
    "start = 0\n",
    "\n",
    "for region in [tamsweg, mariazell, traun, pinzgau]:\n",
    "    \n",
    "    # reindex \n",
    "    idxs_ser = reindex(region, test_indxs)\n",
    "\n",
    "    # trasform indices based on quatering the data in baches of 1000\n",
    "    train_reg.append(transform_indices(idxs_ser['train'], 1000, len(region), start=start))\n",
    "    test_reg.append(transform_indices(idxs_ser['test'], 1000, len(region), start=start))\n",
    "    start += len(region)*4\n",
    "\n",
    "train = np.concatenate(train_reg)\n",
    "test = np.concatenate(test_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     0      1      2 ... 172821 172822 172823]\n",
      "137608\n",
      "[   769    770    771 ... 159593 159594 159595]\n",
      "35216\n"
     ]
    }
   ],
   "source": [
    "print(train)\n",
    "print(train.size)\n",
    "print(test)\n",
    "print(test.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"/home/philipp/Data/edin_dataset/indices/numpy/train_all.npy\", train)\n",
    "np.save(\"/home/philipp/Data/edin_dataset/indices/numpy/test_all.npy\", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    np.save(\"/mnt/data_2/dataset/indices/indices_test_256_df_{}.npy\".format(i), test_reg[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "geo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
